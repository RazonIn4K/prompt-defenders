# Upwork Proposal Snippet – AI Prompt & LLM Security Audit

I offer a hands-on “Prompt Injection Audit + Remediation” engagement powered by the Prompt Defenders scanner. You’ll see exactly how risky prompts are flagged before they ever reach your production LLMs, complete with JSON evidence you can show to product, security, and compliance stakeholders.

During the audit I ingest your scripted prompts, chatbot transcripts, and agent tool calls, then run them through the Prompt Defenders CLI/SDK. Each run produces a risk score, flagged rules, and remediation guidance that maps back to your exact workflows. We collaborate live so your team understands every advisory and how to harden the stack immediately.

The deliverable package includes a remediation blueprint plus CI/runtime integrations so the protections remain in place long after the engagement. This approach has already helped safety-conscious teams close enterprise buyers faster and avoid embarrassing demo-day jailbreaks.

**What I scan**
- Conversation starters, hand-offs, and escalation scripts
- System prompts / hidden instructions for agents or copilots
- Tool/action templates (SQL, API, RPA) that LLMs can invoke
- Live transcripts or redacted chat logs from support/sales bots
- Prompt templates stored in repos, CMS, or workflow builders

**What you receive**
- Risk-ranked JSON report with mapped rules, severities, and mitigations
- Video/loom or live walkthrough explaining every finding
- Integration snippets (Express, FastAPI, workers) showing how to enforce the guardrail inline
- CI/CD recipe so future prompt changes are auto-scanned and builds fail on high risk
- Executive-ready summary describing impact, coverage, and next steps
